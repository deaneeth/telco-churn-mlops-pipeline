# üß† Model Architecture

Comprehensive guide to the machine learning models powering the churn prediction system.

---

## Overview

The pipeline implements **two complementary models**:

1. **Scikit-learn GradientBoostingClassifier** (Primary) - Recall-optimized for production
2. **PySpark RandomForestClassifier** (Secondary) - Distributed training for scale

---

## Primary Model: Scikit-learn GradientBoostingClassifier

### Model Selection Rationale

**Why GradientBoosting?**
- ‚úÖ Excellent performance on tabular data
- ‚úÖ Handles feature interactions naturally
- ‚úÖ Robust to outliers and mixed data types
- ‚úÖ Provides feature importance rankings
- ‚úÖ Lower memory footprint than deep learning

### Architecture

```python
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Full pipeline architecture
pipeline = Pipeline([
    ('preprocessor', ColumnTransformer([
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(drop='first', sparse_output=False), 
         categorical_features)
    ])),
    ('classifier', GradientBoostingClassifier(
        n_estimators=100,
        learning_rate=0.05,
        max_depth=5,
        min_samples_split=50,
        min_samples_leaf=20,
        subsample=0.8,
        random_state=42
    ))
])
```

### Hyperparameters Explained

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| `n_estimators` | 100 | Balance between performance and training time |
| `learning_rate` | 0.05 | Conservative to prevent overfitting |
| `max_depth` | 5 | Limit tree complexity for generalization |
| `min_samples_split` | 50 | Prevent overfitting on small data subsets |
| `min_samples_leaf` | 20 | Ensure meaningful leaf nodes |
| `subsample` | 0.8 | Stochastic gradient boosting for robustness |
| `random_state` | 42 | Reproducibility |

### Recall Optimization Strategy

The model was optimized for **recall** (not accuracy) because:

**Business Context**:
- Customer Lifetime Value (LTV): **$2,000**
- Retention Cost: **$50**
- **Cost Asymmetry**: Missing a churner costs $2,000, but a false alarm costs only $50

**Optimization Techniques**:

1. **Class Weight Balancing**
   ```python
   from sklearn.utils.class_weight import compute_sample_weight
   
   # Compute sample weights to balance classes
   sample_weights = compute_sample_weight(
       class_weight='balanced',
       y=y_train
   )
   
   # Train with weights
   model.fit(X_train, y_train, sample_weight=sample_weights)
   ```

2. **Decision Threshold Tuning**
   ```python
   # Default threshold: 0.5
   # Optimized threshold: 0.35 (favors recall)
   
   # Get probabilities
   y_proba = model.predict_proba(X_test)[:, 1]
   
   # Apply custom threshold
   y_pred_optimized = (y_proba >= 0.35).astype(int)
   ```

3. **Hyperparameter Search**
   ```python
   from sklearn.model_selection import GridSearchCV
   from sklearn.metrics import make_scorer, recall_score
   
   # Use recall as optimization metric
   param_grid = {
       'classifier__n_estimators': [50, 100, 150],
       'classifier__learning_rate': [0.01, 0.05, 0.1],
       'classifier__max_depth': [3, 5, 7]
   }
   
   grid_search = GridSearchCV(
       pipeline,
       param_grid,
       scoring=make_scorer(recall_score),  # Optimize for recall!
       cv=5,
       n_jobs=-1
   )
   ```

### Performance Metrics

#### Before Optimization (Baseline)
```
Accuracy:  80.06%
Precision: 60.00%
Recall:    50.00%  ‚Üê Too low!
F1-Score:  54.55%
ROC-AUC:   84.66%

Confusion Matrix:
                Predicted
              No      Yes
Actual No    1034     102
      Yes     179      94  ‚Üê Missing 179 churners!
```

#### After Recall Optimization (Production)
```
Accuracy:  74.24%  (‚Üì 5.82pp - acceptable)
Precision: 50.93%  (‚Üì 9.07pp - acceptable)
Recall:    80.75%  (‚Üë 30.75pp - KEY WIN!)
F1-Score:  62.46%  (‚Üë 7.91pp)
ROC-AUC:   84.45%  (‚Üì 0.21pp - negligible)

Confusion Matrix:
                Predicted
              No      Yes
Actual No     744     291  (more false positives, but cheap)
      Yes      72     302  ‚Üê Only 72 missed! (60% reduction)

Business Impact:
‚úÖ 115 additional churners caught
‚úÖ $220,150/year additional revenue saved
‚úÖ 23:1 return on retention investment
```

---

## Secondary Model: PySpark RandomForestClassifier

### Purpose

- **Scalability**: Handle larger datasets (millions of rows)
- **Distributed Training**: Leverage cluster computing
- **Comparison**: Validate scikit-learn model performance

### Architecture

```python
from pyspark.ml import Pipeline
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.feature import VectorAssembler, StandardScaler
from pyspark.ml.feature import StringIndexer, OneHotEncoder

# PySpark pipeline
stages = [
    # Encode categorical features
    StringIndexer(inputCol='gender', outputCol='gender_index'),
    OneHotEncoder(inputCol='gender_index', outputCol='gender_vec'),
    # ... (15 categorical features)
    
    # Assemble features
    VectorAssembler(inputCols=feature_cols, outputCol='features'),
    
    # Scale features
    StandardScaler(inputCol='features', outputCol='scaled_features'),
    
    # Train classifier
    RandomForestClassifier(
        featuresCol='scaled_features',
        labelCol='Churn_label',
        numTrees=100,
        maxDepth=10,
        seed=42
    )
]

pipeline = Pipeline(stages=stages)
```

### Performance Metrics

```
ROC-AUC:    83.80%
PR-AUC:     66.15%
Accuracy:   79.12%
Precision:  62.45%
Recall:     68.20%

‚úÖ Validates scikit-learn model
‚úÖ Demonstrates distributed training capability
‚úÖ Production-ready for large-scale data
```

---

## Model Comparison

| Feature | Scikit-learn | PySpark |
|---------|-------------|---------|
| **Algorithm** | GradientBoosting | RandomForest |
| **Primary Use** | Production predictions | Large-scale training |
| **Recall** | 80.75% ‚úÖ | 68.20% |
| **ROC-AUC** | 84.45% ‚úÖ | 83.80% |
| **Training Time** | ~30 seconds | ~2 minutes |
| **Inference Time** | <1ms per sample | ~10ms per sample |
| **Scalability** | Single machine | Distributed cluster |
| **Deployment** | Flask API ‚úÖ | Batch processing |

**Winner**: Scikit-learn for production (better recall, faster inference)

---

## Feature Engineering Pipeline

### Input Features (19)

**Demographic**:
- `gender` - Male/Female
- `SeniorCitizen` - 0/1
- `Partner` - Yes/No
- `Dependents` - Yes/No

**Service Details**:
- `tenure` - Months with company
- `PhoneService` - Yes/No
- `MultipleLines` - Yes/No/No phone service
- `InternetService` - DSL/Fiber optic/No
- `OnlineSecurity` - Yes/No/No internet
- `OnlineBackup` - Yes/No/No internet
- `DeviceProtection` - Yes/No/No internet
- `TechSupport` - Yes/No/No internet
- `StreamingTV` - Yes/No/No internet
- `StreamingMovies` - Yes/No/No internet

**Billing**:
- `Contract` - Month-to-month/One year/Two year
- `PaperlessBilling` - Yes/No
- `PaymentMethod` - Electronic check/Mailed check/Bank transfer/Credit card
- `MonthlyCharges` - Numeric
- `TotalCharges` - Numeric

### Output Features (45)

After preprocessing:
- **Numerical** (4): tenure, MonthlyCharges, TotalCharges, SeniorCitizen
- **One-Hot Encoded** (41): All categorical features

**Encoding Example**:
```python
# Input:
{'gender': 'Female', 'Contract': 'Month-to-month'}

# Output:
{
  'gender_Female': 1, 'gender_Male': 0,
  'Contract_Month-to-month': 1,
  'Contract_One year': 0,
  'Contract_Two year': 0
}
```

### Feature Importance (Top 10)

From trained GradientBoostingClassifier:

| Rank | Feature | Importance | Interpretation |
|------|---------|------------|----------------|
| 1 | `tenure` | 0.285 | Most important! Longer tenure = less churn |
| 2 | `TotalCharges` | 0.198 | Higher charges correlate with stability |
| 3 | `MonthlyCharges` | 0.156 | Price sensitivity indicator |
| 4 | `Contract_Month-to-month` | 0.112 | Highest churn risk |
| 5 | `InternetService_Fiber optic` | 0.067 | Higher churn than DSL |
| 6 | `PaymentMethod_Electronic check` | 0.048 | Churn risk indicator |
| 7 | `OnlineSecurity_No` | 0.032 | Lack of services = higher churn |
| 8 | `TechSupport_No` | 0.028 | Support usage correlates with retention |
| 9 | `Contract_Two year` | 0.024 | Lowest churn risk |
| 10 | `PaperlessBilling_Yes` | 0.019 | Minor churn indicator |

---

## Model Versioning

Models are versioned using MLflow:

```
mlruns/
‚îú‚îÄ‚îÄ experiment_1/
‚îÇ   ‚îú‚îÄ‚îÄ run_1/ (baseline, recall: 50%)
‚îÇ   ‚îú‚îÄ‚îÄ run_2/ (threshold tuning, recall: 65%)
‚îÇ   ‚îú‚îÄ‚îÄ run_3/ (class weights, recall: 72%)
‚îÇ   ‚îî‚îÄ‚îÄ run_17/ (production, recall: 80.75%) ‚úÖ
```

**Production Model**: Run #17
- **Path**: `artifacts/models/sklearn_pipeline.joblib`
- **Size**: ~200KB
- **Created**: October 2025
- **Status**: ‚úÖ Production

---

## Next Steps

- **[Model Training](Model-Training)** - Train your own model
- **[Model Evaluation](Model-Evaluation)** - Detailed metrics
- **[Feature Engineering](Feature-Engineering)** - Data preprocessing
- **[MLflow Setup](MLflow-Setup)** - Track experiments

---

[‚Üê Back to Home](Home) | [Next: Feature Engineering ‚Üí](Feature-Engineering)
